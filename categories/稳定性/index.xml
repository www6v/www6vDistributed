<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>稳定性 on Distributed</title>
    <link>https://www6v.github.io/www6vDistributed/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/</link>
    <description>Recent content in 稳定性 on Distributed</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Wed, 01 Feb 2023 16:14:47 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vDistributed/categories/%E7%A8%B3%E5%AE%9A%E6%80%A7/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SRE 总结</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sre/</link>
      <pubDate>Sun, 13 Mar 2022 22:36:50 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sre/</guid>
      <description>SRE [1] # SRE = PE（Production Engineer） + 工具平台开发 + 稳定性平台开发 工具平台团队，负责效能工具的研发，比如实现 CMDB、运维自动化、持续交付流水线以 及部分技术运营报表的实现，为基础运维和应用运维提供效率平台支持。 稳定性平台团队，负责稳定性保障相关的标准和平台，比如监控、服务治理相关的限流降 级、全链路跟踪、容量压测和规划。 组织架构图 [1] # 故障复盘 [2] # 黄金三问 第一问：故障原因有哪些？ 第二问：我们做什么，怎么做才能确保下次不会再出现类似故障？ 第三问：当时如果我们做了什么，可以用更短的时间恢复业务？ 故障判定的三原则 健壮性原则。 第三方默认无责。 分段判定原则。 5W 分析法 Google SRE Principle [5] # 运营是软件问题 服务水平目标SLO 减少琐事 用自动化的方式减少琐事 自动化 ** 统一环境， IaC CaC， ** IaC: Terraform, Ansible, Pulumi 生产环境中进行测试 统一 版本管理，制品库，cmdb 可观测性 降低失败成本 复盘 从失败中学习 共享所有权 个人安全，责任共担 拥抱风险 + 错误预算 Google SRE 实践总结 [5] # 确保长期关注研发工作 在保障SLO的前提下最大化迭代速度 监控系统 + insight，根因 应急事件处理 变更管理 ITIL 需求预测和容量规划 + AIOps 资源部署 效率与性能 参考 # 《09｜案例：互联网典型的SRE组织架构是怎样的？》 赵成 《08｜故障复盘：黄金三问与判定三原则》 赵成 xxx SRE 的工作介绍 SRE大佬 未 SRE核心概念与可观测性介绍 中国DevOps社区 刘峰 +《SRE google 运维解密》</description>
    </item>
    <item>
      <title>故障模型-应用层</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/%E6%95%85%E9%9A%9C%E6%A8%A1%E5%9E%8B/faultModel1/</link>
      <pubDate>Sat, 27 Oct 2018 14:39:20 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/%E6%95%85%E9%9A%9C%E6%A8%A1%E5%9E%8B/faultModel1/</guid>
      <description>故障模型-Application &amp;amp; Data # OOM # + 堆内 【10】&#xD;- PermGen&#xD;+ 原因：反射类多&#xD;+ 解决&#xD;先jmap，后btrace【11、12 case2】&#xD;- heap&#xD;解决：对比Fullgc后的相同对象的数量、大小&#xD;+ 堆外Native&#xD;参考 Go to Page self 如何排查Java内存泄露(内附各种排查工具介绍) 不闻 生产环境下持久带满导致FullGC，如何跟踪 Go to Page self 应用性能变差 # + 原因&#xD;- 锁 - heap&#xD;+ fullgc后没有空间&#xD;原因：内存泄露&#xD;工具：heap dump&#xD;+ fullgc后有空间&#xD;解决：设置门槛，过滤大量短生命周期对象【12 case1，13】&#xD;- gc停顿长&#xD;解决：【12 case3，13】&#xD;参考 Go to Page self Go to Page self 听阿里巴巴JVM工程师为你分析常见Java故障案例 *** Load过高 # + cpu load高【13】&#xD;- 启动阶段&#xD;原因：JIT编译器&#xD;解决：分层编译&#xD;- 运行阶段&#xD;原因：有热点方法&#xD;工具：MAT&#xD;- 解决&#xD;工具【8、9】&#xD;数据收集 4、5&#xD;参考</description>
    </item>
    <item>
      <title>稳定性总结</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E7%A8%B3%E5%AE%9A%E6%80%A7/stability/</link>
      <pubDate>Tue, 09 May 2017 22:34:54 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E7%A8%B3%E5%AE%9A%E6%80%A7/stability/</guid>
      <description>&#xA;关键词: 容量规划, 压测, 强弱依赖, 关键词: 故障模型, 故障演练, 故障注入&#xA;稳定性总结 # 参考： # 超全总结 | 阿里如何应对电商故障？神秘演练细节曝光 阿里巴巴-周洋（花名中亭） 故障注入， 故障演练 稳定性思考-强弱依赖 阿里中间件团队博客 稳定性思考-强弱依赖2 阿里中间件团队博客 中间件技术及双十一实践·稳定性平台篇 阿里中间件（Aliware） 强弱依赖， 容量规划 &amp;laquo;尽在双11阿里巴巴技术演进与超越&amp;raquo; </description>
    </item>
    <item>
      <title>故障模型-中间件层</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/%E6%95%85%E9%9A%9C%E6%A8%A1%E5%9E%8B/faultModel2/</link>
      <pubDate>Thu, 03 May 2018 21:59:42 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/%E6%95%85%E9%9A%9C%E6%A8%A1%E5%9E%8B/faultModel2/</guid>
      <description>故障模型-中间件层 # 故障模型-Runtime&amp;amp;Middleware&amp;amp;OS 负载均衡失效 数据库 数据库热点 数据库连接满 数据库宕机 数据库同步延迟 数据库主备延迟【参考2】 缓存 缓存热点【参考1】 缓存限流 OS资源 CPU抢占 案例 : HashMap并发访问，CPU100%【参考1】 案例：正则表达式回溯，CPU100% 内存抢占 案例：OOM killer 上下文切换 参考 # 大纲 # 超全总结 | 阿里如何应对电商故障？神秘演练细节曝光 阿里巴巴 周洋 Runtime &amp;amp; Middleware &amp;amp; OS # Go to Page self&#xA;UCloud高可用数据库UDB主从复制延时的解决</description>
    </item>
    <item>
      <title>故障模型-基础设施层</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/%E6%95%85%E9%9A%9C%E6%A8%A1%E5%9E%8B/faultModel3/</link>
      <pubDate>Thu, 03 May 2018 21:59:57 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/%E6%95%85%E9%9A%9C%E6%A8%A1%E5%9E%8B/faultModel3/</guid>
      <description>&#xA;故障模型-基础设施层 # 故障模型-Virtualization&amp;amp;Storage&amp;amp;Networking 服务器宕机&amp;amp;假死 断电 解决：异地多活 超卖 混和部署【3】 存储【2】 磁盘满，坏 不可写，不可读 网络【1】 网络抖动、丢包、超时 网卡满 DNS故障 断网 参考 # Virtualization &amp;amp; Storage &amp;amp; Networking # Kubernetes 网络疑难杂症排查分享 腾讯云 *** kubernetes 最佳实践：处理容器数据磁盘被写满 腾讯云 百度大规模战略性混部系统演进 </description>
    </item>
    <item>
      <title>《SRE 工作手册》</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sreWorkbook/</link>
      <pubDate>Wed, 01 Feb 2023 16:14:47 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sreWorkbook/</guid>
      <description>参考 # SRE 实践的知识体系梳理</description>
    </item>
    <item>
      <title>SRE 五大根基</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sreWorkbookBasic/</link>
      <pubDate>Wed, 27 Apr 2022 22:33:17 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sreWorkbookBasic/</guid>
      <description>&#xA;目录 # SRE五大根基 # 实践SLO # 监控 # 告警 # 减少琐事 # 简单化 # 参考 # 《Google SRE工作手册》第二期SRE五大根基之一：SLO V *** 《Google SRE工作手册》第二期SRE五大根基之二：监控 V *** {% post_link &amp;lsquo;sreWorkbook&amp;rsquo; %} self {% post_link &amp;lsquo;sreWorkbookBasicSLO&amp;rsquo; %} </description>
    </item>
    <item>
      <title>SRE 五大根基-SLO</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sreWorkbookBasicSLO/</link>
      <pubDate>Mon, 02 May 2022 18:06:40 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sreWorkbookBasicSLO/</guid>
      <description>&#xA;目录 # SRE 五大根基 之 SLO[1] # 步骤1. 制定SLO # 服务的SLO # VALET[Home Depot] Volume Avail Latency Errors Ticket 数据服务的SLO # Go to Page {% post_link &amp;lsquo;kafkaSLO&amp;rsquo; %} SLI # 服务类型 SLI类型 请求驱动 可用性，延迟，质量 流水线 时效性，正确率，覆盖率 存储 持久性 步骤2. 获得干系人认同 # SLO 仪表板[趋势] # 步骤3. 持续监控 改进SLO # 变更SLO 变更SLI实现 着手于现实的SLO 迭代 步骤4. 错误预算 SLO决策 # 基于SLO和错误预算的决策 # 步骤5. 进阶 # 用户旅程建模 依赖关系建模 参考 # 《Google SRE工作手册》第二期SRE五大根基之一：SLO V *** 《Google SRE工作手册》 第二章 </description>
    </item>
    <item>
      <title>SRE 五大根基-报警</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sreWorkbookBasicAlert/</link>
      <pubDate>Mon, 02 May 2022 18:51:42 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/SRE/SRE/sreWorkbookBasicAlert/</guid>
      <description>&#xA;告警设定考量 # 精准率&#xA;减少误告警&#xA;查全率&#xA;减少漏告警&#xA;检测用时&#xA;过长 影响错误预算 重置用时&#xA;过长 增长内存和IO开销 告警设定方法 # 基础 方法1 目标错误率 &amp;gt;= SLO阈值 window 方法2 延长报警时间窗口 方法3 延长告警触发前的持续时间 燃烧率 方法4 根据燃烧率发出告警 方法5 基于多个燃烧率的告警 方法6 基于多个窗口 多个燃烧率的告警 参考 # 《Google SRE工作手册》第四期基于SLO的告警配置及实践分享 V 《Google SRE工作手册》 第5章 </description>
    </item>
    <item>
      <title>容量保障与全链路压测</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%AE%B9%E9%87%8F%E4%BF%9D%E9%9A%9C/capacityGuarantee/</link>
      <pubDate>Sun, 13 Mar 2022 15:58:58 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E5%AE%B9%E9%87%8F%E4%BF%9D%E9%9A%9C/capacityGuarantee/</guid>
      <description>容量保障Overview[2] # 大促容量保障的三项重点工作： 大促流量预估 大促容量测试 大促容量保障预案 容量预测 # 容量预测[1] # 我首先给出了**“皮尔逊相关系数”**这个工具，对服务 TPS 和 CPU 利用率之间的相关度进 行了定量分析，根据相关度的强弱，分别采取不同策略。其中，重点讲到了在两者弱相关 时的应对策略，如果能够穷举出尽可能多的相关特征，可以通过特征选取的方式对服务进 行画像，提升预测准确率；如果特征非常难找，那么可以依靠概率表的方式曲线救国。&#xA;随着服务不断迭代，容量也在不断变化，我与你分析的第二个问题，就是如何平衡好服务 迭代和容量预测频率的关系。根据服务发布窗口（或其他变更时间点）建立滑动窗口机 制，既保证了在服务变更后能够尽快地更新模型，又不至于带来大量的计算量，是一个不 错的实践方式。&#xA;业务场景变化也会导致容量变化，针对这个问题，我结合之前提到的全链路压测工作，通 过建立全链路压测和容量预测双向校准的机制，提前对变化的业务场景进行预测，识别容 量风险。&#xA;全链路压测 # 核心功能[4] # 压测-部署架构 # 施压机的分布[3]&#xA;大部分仍然是跟线上系统在同机房内，少量会在公有云节点上 以将全球（主要是国内）的 CDN 节点作为施压机 更加真实地模拟真实用户从全球节点进入的真实访问流量 成本过高，技术条件和细节难 压测的读写流量[3]&#xA;读流量 写流量 对压测的写请求做专门的标记。 当请求要写数据库时，由分布式数据库的中间件框架中的逻辑来判断这个请求是否是压测请求，如果是压测写请求则路由到对应的影子库中，而不是直接写到线上正式的库中。 改造 全链路压测[5] # 数据隔离 物理隔离 vs. 逻辑隔离 [见表1] 中间件改造 eg. MQ改造 ​ Producer: 判断请求带压测标识，转换到数据体（msg）中 ​ Consumer: 判断数据（msg）中有压测标识， 恢复压测标识至请求中 应用服务改造 绕开限制逻辑 数据隔离前置 Mock 逻辑 ​ 表1 逻辑隔离 vs.</description>
    </item>
    <item>
      <title>TCP故障模式</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E7%A8%B3%E5%AE%9A%E6%80%A7/tcpFault/</link>
      <pubDate>Sat, 08 Aug 2020 23:17:36 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E7%A8%B3%E5%AE%9A%E6%80%A7/tcpFault/</guid>
      <description>一. 故障模式 # 对端无FIN包发送 # 网络中断 read TIMEOUT（setsockopt）&#xA;先write再read， 持续重传直至TIMEOUT。 之后再write()， 返回SIGPIPE信号（Broken Pipe）。&#xA;write Unreachable&#xA;系统奔溃（如断电） read()或者write()持续重传直至TIMEOUT&#xA;对端重启，read()或者write()返回RST。 read（）调用返回Connection Reset。write()返回SIGPIPE信号（Broken Pipe）。&#xA;对端有FIN包发送（如程序奔溃） # read直接感知FIN&#xA;没有read&#xA;如果不read没办法得到TCP对端的响应.&#xA;通过write()产生RST， read（）感知RST（Connection reset by peer）。&#xA;向一个关闭连接连续写导致SIGPIPE信号（Broken Pipe）。&#xA;二. Java对应的错误 # java.net.SocketTimeoutException # java.net.SocketException: Connection reset/Connect reset by peer: Socket write error # 指连接被重置。这里有两种情况，分别对应两种错误：第一种情况是通信的一方已经将Socket 关闭，可能是主动关闭或者是因为异常退出， 这时如果通信的另一方还在写数据，就会触发这个异常**（Connect reset by peer）； 如果对方还在尝试从 TCP 连接中读数据**，则会抛出 Connection reset 异常。&#xA;为了避免这些异常发生，在编写网络通信程序时要确保： 程序退出前要主动关闭所有的网络连接。 检测通信的另一方的关闭连接操作，当发现另一方关闭连接后自己也要关闭该连接。&#xA;java.net.SocketException: Broken pipe # 指通信管道已坏。发生这个异常的场景是，通信的一方在收到“Connect reset by peer:Socket write error”后，如果再继续写数据则会抛出 Broken pipe 异常，解决方法同上。</description>
    </item>
    <item>
      <title>宕机检测-Lease、心跳</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E7%A8%B3%E5%AE%9A%E6%80%A7/crashDetect/</link>
      <pubDate>Sat, 12 Oct 2019 10:50:19 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E7%A8%B3%E5%AE%9A%E6%80%A7/crashDetect/</guid>
      <description>&#xA;Lease # Kubernetes: 引入了一个新的 build-in Lease API[2]&#xA;心跳 # 模式： ping-ping模式, ping-pong模式&#xA;raft： 心跳选主&#xA;参考 # 【分布式系统工程实现】如何检测一台机器是否宕机？ 阿里中间件 *** 当 K8s 集群达到万级规模，阿里巴巴如何解决系统各组件性能问题？ 曾凡松（逐灵） *** 《面向模式的软件架构-卷4》 20.15节 </description>
    </item>
    <item>
      <title>混沌工程</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B/chaosEngineering/</link>
      <pubDate>Tue, 24 Sep 2019 22:20:50 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E7%A8%B3%E5%AE%9A%E6%80%A7/%E6%B7%B7%E6%B2%8C%E5%B7%A5%E7%A8%8B/chaosEngineering/</guid>
      <description>&#xA;混沌工程实践[1,2] # 原则 # 成熟度 # 混沌工程实施步骤 # 制订混沌实验计划 定义系统稳态指标 做出系统容错行为假设 执行混沌实验 检查系统稳态指标 记录&amp;amp;恢复混沌实验 修复发现的问题 自动化持续进行验证 混沌工程产品 # 相关产品ChaosBlade 故障注入 参考 # 分布式服务架构下的混沌工程实践 阿里 穹谷 *** 混沌工程介绍与实践 阿里 穹谷 Netflix 混沌工程手册 Part 1：混沌工程简介 Netflix 混沌工程手册 Part 2：混沌工程原则 Netflix 混沌工程手册 Part 3：实践方法 </description>
    </item>
    <item>
      <title>Split Brain</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E4%B8%80%E8%87%B4%E6%80%A7/splitBrain/</link>
      <pubDate>Sun, 19 Feb 2017 23:44:11 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E4%B8%80%E8%87%B4%E6%80%A7/splitBrain/</guid>
      <description>关键词: 脑裂, fence, Quorums , epoch&#xA;脑裂： 类似 CAP中的P Partition tolerance(分区容错性): 网络分区发生时，一致性和可用性两难全&#xA;一. 通用解决方案 # Quorums Redundant communications，冗余通信的方式 Fencing 二. 系统 # / 现象 解决方案 kafka kafka脑裂现象:1. 存在多个controller 2. consumer的splitBrain controller使用epoch来避免脑裂 elastic search 配置discovery.zen.minimum_master_nodes，类似Quorums zookeeper 两个leader[3] Quorums leader单调递增的epoch raft脑裂 两个majority [2] Quorums + term redis脑裂、mysql脑裂&#xA;参考: # redis 脑裂等极端情况分析 Redis Cluster is not able to guarantee strong consistency. / In general Redis + Sentinel as a whole are a an eventually consistent system</description>
    </item>
  </channel>
</rss>
