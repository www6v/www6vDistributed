<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Linux on Distributed</title>
    <link>https://www6v.github.io/www6vDistributed/categories/linux/</link>
    <description>Recent content in Linux on Distributed</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Sun, 16 Aug 2020 12:45:15 +0000</lastBuildDate>
    <atom:link href="https://www6v.github.io/www6vDistributed/categories/linux/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Linux性能优化 之 cpu优化</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/Linux%E6%80%A7%E8%83%BD/linuxPerformance-cpu/</link>
      <pubDate>Sun, 16 Aug 2020 12:45:15 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/Linux%E6%80%A7%E8%83%BD/linuxPerformance-cpu/</guid>
      <description>&#xA;一. 工具与指标 # 二. 最常用的cpu工具 # 最常用的cpu工具 工具中指标之间的关系&#xA;三. cpu优化案例 # 1. 上下文切换的案例。 # 自愿上下文切换，是指进程无法获取所需资源，导致的上下文切换。比如说， I/O、内存等系统资源不足时，就会发生自愿上下文切换。 非自愿上下文切换，则是指进程由于时间片已到等原因，被系统强制调度，进而发生的上下文切换。比如说，大量进程都在争抢 CPU 时，就容易发生非自愿上下文切换。&#xA;先用 vmstat ，查看了系统的上下文切换次数和中断次数；然后通过pidstat ，观察了进程的自愿上下文切换和非自愿上下文切换情况；最后通过 pidstat ，观察了线程的上下文切换情况，找出了上下文切换次数增多的根源，也就是我们的基准测试工具 sysbench。&#xA;2. 进程 CPU 使用率升高的案例 # 可能代码里有死循环&#xA;3. 不可中断进程和僵尸进程的案例 # 先用 top 观察到了 iowait 升高的问题，并发现了大量的不可中断进程和僵尸进程；接着用 dstat 发现是这是由磁盘读导致的，于是又通过 pidstat 找出了相关的进程。但我们用 strace 查看进程系统调用却失败了，最终还是用 perf 分析进程调用链，才发现根源在于磁盘直接 I/O 。 僵尸进程是因为父进程没有回收子进程的资源而出现的，那么，要解决掉它们，就要找到它们的根儿，也就是找出父进程，然后在父进程里解决。&#xA;4.软中断的案例。 # 通过 top 观察到，系统的软中断 CPU 使用率升高；接着查看/proc/softirqs， 找到了几种变化速率较快的软中断；然后通过 sar 命令，发现是网络小包的问题，最后再用 tcpdump ，找出网络帧的类型和来源，确定是一个SYN FLOOD 攻击导致的。&#xA;参考： # &amp;laquo;Linux性能优化实战 - 11 - 套路篇：如何迅速分析出系统CPU的瓶颈在哪里？&amp;raquo; 倪朋飞 &amp;laquo;Linux性能优化实战 - 04讲基础篇：经常说的CPU上下文切换是什么意思（下）&amp;raquo; 倪朋飞 </description>
    </item>
    <item>
      <title>TIME_WAIT和优化</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/%E7%BD%91%E7%BB%9C/tcpTimewait/</link>
      <pubDate>Sun, 09 Aug 2020 12:03:41 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/%E7%BD%91%E7%BB%9C/tcpTimewait/</guid>
      <description>故障现象 # 让我们先从一例线上故障说起。在一次升级线上应用服务之后，我们发现该服务的可用性变 得时好时坏，一段时间可以对外提供服务，一段时间突然又不可以， 大家都百思不得其解。 运维同学登录到服务所在的主机上，使用 netstat 命令查看后才发现，主机上有成千上万处 于 TIME_WAIT 状态的连接。&#xA;经过层层剖析后，我们发现罪魁祸首就是 TIME_WAIT。为什么呢？我们这个应用服务需要 通过发起 TCP 连接对外提供服务。每个连接会占用一个本地端口，当在高并发的情况下， TIME_WAIT 状态的连接过多，多到把本机可用的端口耗尽，应用服务对外表现的症状，就 是不能正常工作了。当过了一段时间之后，处于 TIME_WAIT 的连接被系统回收并关闭 后，释放出本地端口可供使用，应用服务对外表现为，可以正常工作。这样周而复始，便会 出现了一会儿不可以，过一两分钟又可以正常工作的现象。&#xA;TIME_WAIT概念和作用 # 概念 # 只有发起连接终止的一方会进入 TIME_WAIT 状态。 TIME_WAIT停留持续时间是固定的，是最长分节生命期 MSL（maximumsegment lifetime）的两倍（2MSL）。Linux系统里有一个硬编码的字段，名称为TCP_IMEWAIT_LEN，其值为 60 秒。也就是说，Linux 系统停留在 TIME_WAIT 的时间为固定的 60 秒。 作用 # 这样做是为了确保最后的 ACK 能让被动关闭方接收（可能丢失ACK后重传ACK），从而帮助其正常关闭。 第二个理由和连接“化身”和报文迷走有关系，为了让旧连接的重复分节在网络中自然消失。 TIME_WAIT的副作用和优化 # TCP和TIME_WAIT # 当连接的一方主动关闭连接，在接收到对端的 FIN 报文之后，主动关闭连接的一方会在 TIME_WAIT 这个状态里停留一段时间，这个时间大约为 2MSL。&#xA;主动关闭连接的一方可以是客户端，也可以是服务端； 副作用1 主动关闭连接的一方 是客户端； 副作用2 主动关闭连接的一方 是服务端；&#xA;副作用和优化 # 副作用1 对端口资源的占用，一个 TCP 连接至少消耗一个本地端口</description>
    </item>
    <item>
      <title>Linux性能优化</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/Linux%E6%80%A7%E8%83%BD/linuxPerformance/</link>
      <pubDate>Thu, 08 Aug 2019 19:43:38 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/Linux%E6%80%A7%E8%83%BD/linuxPerformance/</guid>
      <description>&#xA;最常用的cpu工具 # memory tool # IO tool # Buffer是对磁盘数据的缓存，而Cache是文件数据的缓存，它们既会用在读请求中，也会用在写请求中。&#xA;参考 # &amp;laquo;Linux性能优化实战 11 - 套路篇：如何迅速分析出系统CPU的瓶颈在哪里？&amp;raquo; 倪朋飞 &amp;laquo;Linux性能优化实战 21 - 套路篇：如何“快准狠”找到系统内存的问题？&amp;raquo; 倪朋飞 &amp;laquo;Linux性能优化实战 30 - 套路篇：如何迅速分析出系统IO的瓶颈在哪里？&amp;raquo; 倪朋飞 &amp;laquo;Linux性能优化实战 16 - 基础篇：怎么理解内存中的Buffer和Cache？&amp;raquo; 倪朋飞 </description>
    </item>
    <item>
      <title>TCP流控和拥塞控制</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/%E7%BD%91%E7%BB%9C/tcpUdpControlCongestion/</link>
      <pubDate>Wed, 07 Aug 2019 13:52:09 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/%E7%BD%91%E7%BB%9C/tcpUdpControlCongestion/</guid>
      <description>&#xA;TCP拥塞控制 # TCP拥塞控制-快速重传 # 快速重传 # 拥塞窗口是为了怕把网络塞满，在出现丢包的时候减少发送速度. 滑动窗口就是为了怕把接收方塞满，而控制发送速度.&#xA;参考: # TCP 的那些事儿（下） （四）：网络性能排查之TCP重传与重复ACK 怎么让不可靠的UDP可靠？ 趣谈Linux操作系统 - 45-发送网络包（上）：如何表达我们想让合作伙伴做什么？ </description>
    </item>
    <item>
      <title>Linux性能分析</title>
      <link>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/Linux%E6%80%A7%E8%83%BD/linuxProfile/</link>
      <pubDate>Wed, 26 Dec 2018 23:23:18 +0000</pubDate>
      <guid>https://www6v.github.io/www6vDistributed/docs/%E6%80%A7%E8%83%BD/Linux%E6%80%A7%E8%83%BD/linuxProfile/</guid>
      <description>Linux observability tools | Linux 性能观测工具 # Linux性能观测工具&#xA;快速性能诊断(快速体检) # 1. 系统平均负载 # # 0.25- 1分钟负载 ， 0.22-5分钟负载， 0.23-15分钟负载&#xD;[root@10-25-3-55 /]# uptime&#xD;23:02:19 up 285 days, 11:37, 1 user, load average: 0.25, 0.22, 0.23&#xD;# 如果cpu个数是4， 则平均负载4是合理的。&#xD;[root@10-23-25-248]$grep &amp;#39;model name&amp;#39; /proc/cpuinfo | wc -l&#xD;4 平均负载: 单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是单位时间内的活跃进程数。&#xA;场景 CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的； I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高； 大量等待 CPU 的进程调度也会导致平均负载升高，此时的CPU使用率也会比较高。&#xA;2. dmesg | tail : 系统信息 导致性能问题的错误 # [9927609.</description>
    </item>
  </channel>
</rss>
